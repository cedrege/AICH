{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to solve the kaggle competition \"Child Mind Institute - Detect Sleep States\"\n",
    "Link to the competition: https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states\n",
    "\n",
    "\n",
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib plotly pandas numpy tqdm scikit-learn pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from score import score\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score, precision_score, average_precision_score\n",
    "import wandb\n",
    "from abc import ABC, abstractmethod #, classmethod\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pickle import dump, load\n",
    "from custom_enums import ModelTrainingType\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# wandb.login() requires you to get your API key from your account settings\n",
    "# open the weights and biases website https://wandb.ai/login and login to your account\n",
    "# then go to your account settings and copy the API key\n",
    "# paste it in the input box and hit enter\n",
    "\n",
    "#wandb.login() #TODO: uncomment this line to login to your account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start a new wandb run to track this script\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"my-awesome-project\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": 0.02,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"CIFAR-100\",\n",
    "#     \"epochs\": 10,\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to switch between different models from different libraries at a glance, we implement an interface called `IPipelineRequirements`. This allows us to make the pipleine even more robust and easier to extend upon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPipelineRequirements(ABC):\n",
    "    @abstractmethod\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def load(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model is the baseline model, which just takes the mean over all onset and wakeup times and tries to predict `onset` and `wakeup` events with the calculated time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(IPipelineRequirements):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "    def predict(self):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "    def save(self):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "    def load(self):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = BaselineModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerous studies have concentrated on applications using `RandomForest`. The primary motivation for this preference is the model's inherent transparency in decision-making processes, which are readily identifiable in such models. Subsequent to the BaselineModel, efforts have been made to abstract models from the Scikit-learn library. Fortunately, the majority of models within their API exhibit consistent implementation patterns, facilitating their integration into the processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkLearnModel(IPipelineRequirements):\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        self.load(model_path)\n",
    "\n",
    "    def __init__(self, model, identifier, scaler=StandardScaler, sk_model_params=None):\n",
    "        self._model = model\n",
    "        self._scaler = scaler if not callable(scaler) else scaler() # if scaler is a classpointer, instantiate it\n",
    "        self.identifier = identifier\n",
    "        self._model_params = sk_model_params\n",
    "\n",
    "    def train(self, X, y, not_scaled=False, **kwargs):\n",
    "        if not_scaled:\n",
    "            X = self._scaler.transform(X)\n",
    "\n",
    "        # due to the big dataset we need to check wich model was instantiated and do some model\n",
    "        # specific stuff to enable us to train the model in batches\n",
    "        if isinstance(self._model, RandomForestClassifier):\n",
    "            new_estimators = kwargs['add_estimators'] if 'add_estimators' in kwargs else 50\n",
    "            if self._model.warm_start: self._model.n_estimators += new_estimators\n",
    "            print(f'Current estimator increased to {self._model.n_estimators}, {new_estimators} added this round.')\n",
    "        # if isinstance(self._model, SVC):\n",
    "        #     pass\n",
    "\n",
    "        self._model.fit(X, y)\n",
    "\n",
    "    def predict(self, X, not_scaled=False):\n",
    "        if not self._model: raise ValueError('Please load or train a model first.')\n",
    "        if not_scaled:\n",
    "            if not self._scaler: raise ValueError('Please load or fit a scaler first.')\n",
    "            X = self._scaler.transform(X)\n",
    "        return self._model.predict(X)\n",
    "\n",
    "    def save(self):\n",
    "        try:\n",
    "            Path.mkdir(Path('models'), exist_ok=False)\n",
    "            with open(f'models/model_{self.identifier}.pkl', 'wb') as f:\n",
    "                dump(self._model, f)\n",
    "            with open(f'models/scaler_{self.identifier}.pkl', 'wb') as f:\n",
    "                dump(self._scaler, f)\n",
    "        except:\n",
    "            raise ValueError('Unable to save model and scaler.')\n",
    "\n",
    "    def load(self, filepath):\n",
    "        try:\n",
    "            # load model and scaler\n",
    "            if os.path.isfile(filepath):\n",
    "                print(f'Loading model from {filepath}')\n",
    "                with open(filepath, 'rb') as f:\n",
    "                    self._model = load(f)\n",
    "            scaler_path = f'{os.path.split(filepath)[0]}/scaler_{os.path.split(filepath)[1].split(\".\")[0].split(\"_\")[1]}.pkl'\n",
    "            if os.path.isfile(scaler_path):\n",
    "                print(f'Loading scaler from {scaler_path}')\n",
    "                with open(filepath, 'rb') as f:\n",
    "                    self._scaler = load(f)\n",
    "\n",
    "            # extract identifier from filename\n",
    "            self._identifier = filepath.split('_')[1].split('.')[0]\n",
    "        except (FileNotFoundError) as e:\n",
    "                print(f'File {e} not found')\n",
    "                raise ValueError('Filepath is not valid. Unable to load model and scaler.')\n",
    "        except (IndexError) as e:\n",
    "                print(f'The name of the file does not implement the convention \"<model|scaler>_<some identifier>\".')\n",
    "                raise ValueError('Filepath is not valid. Unable to load model and scaler.')\n",
    "        except (Exception) as e:\n",
    "            print(f'Something went wrong. {e}')\n",
    "            raise ValueError('Unknown Error.')\n",
    "\n",
    "    def evaluate(self, X, y, scoreFx=None, not_scaled=False, prepredicted=None):\n",
    "        if not scoreFx:\n",
    "            raise ValueError('Please provide a score function.')\n",
    "        if not self._model:\n",
    "            raise ValueError('Please load or train a model first.')\n",
    "        if not_scaled and prepredicted == None:\n",
    "            if not self._scaler: raise ValueError('Please load or fit a scaler first.')\n",
    "            X = self._scaler.transform(X)\n",
    "            \n",
    "        #TODO: Does score FX require an array of predictions or a single prediction?\n",
    "        #TODO: TEST PARAMS OF SCORE FX!!!!\n",
    "        return scoreFx(y, prepredicted if prepredicted != None else self._model.predict(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristics method to get the right event under the constraints given by Child Mind Institue\n",
    "\n",
    "* A single sleep period must be at least 30 minutes in length\n",
    "* A single sleep period can be interrupted by bouts of activity that do not exceed 30 consecutive minutes\n",
    "* No sleep windows can be detected unless the watch is deemed to be worn for the duration (elaborated upon, below)\n",
    "* The longest sleep window during the night is the only one which is recorded\n",
    "* If no valid sleep window is identifiable, neither an onset nor a wakeup event is recorded for that night.\n",
    "* Sleep events do not need to straddle the day-line, and therefore there is no hard rule defining how many may occur within a given period. However, no more than one window should be assigned per night. For example, it is valid for an individual to have a sleep window from 01h00–06h00 and 19h00–23h30 in the same calendar day, though assigned to consecutive nights\n",
    "* There are roughly as many nights recorded for a series as there are 24-hour periods in that series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_filter(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the training and the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise(ValueError('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = '../data/train_20231021'\n",
    "TRAIN_DATA = '../data/train_20231021_20M'\n",
    "VALIDATION_DATA = '../data/validation_20231021'\n",
    "\n",
    "# figure out series id mapping\n",
    "if not 'series_id_mapping' in vars():\n",
    "    series_id_mapping = {'train': dict(), 'validation': dict()}\n",
    "    t = pq.ParquetDataset(TRAIN_DATA).read(columns=['series_id'])\n",
    "    for i, data in enumerate(t.to_pandas()['series_id'].unique()):\n",
    "        series_id_mapping['train'][data] = i\n",
    "    v = pq.ParquetDataset(VALIDATION_DATA).read(columns=['series_id'])\n",
    "    for i, data in enumerate(v.to_pandas()['series_id'].unique()):\n",
    "        series_id_mapping['validation'][data] = i\n",
    "    del t, v\n",
    "    gc.collect()\n",
    "\n",
    "train_dataset_length = pq.ParquetFile(TRAIN_DATA).metadata.num_rows\n",
    "\n",
    "def dataloader_full_dataset(validation=False):\n",
    "    return pd.read_parquet(VALIDATION_DATA if validation else TRAIN_DATA)\n",
    "\n",
    "def dataloader(validation=False, batch_size=5_000_000):\n",
    "    parquet_file = pq.ParquetFile(VALIDATION_DATA if validation else TRAIN_DATA)\n",
    "    for i in parquet_file.iter_batches(batch_size=batch_size):\n",
    "        yield i.to_pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# define all the combinations of models and features\n",
    "models_and_hyperparams = {\n",
    "    RandomForestClassifier: {\n",
    "        'params': {\n",
    "            'n_estimators': [200, 300, 400],\n",
    "            'max_depth': [10, 10, 20, None],\n",
    "            'random_state': [0],\n",
    "            #'criterion': ['gini', 'entropy', 'log_loss],\n",
    "            'warm_start': [True]\n",
    "        },\n",
    "        'modeltype': SkLearnModel,\n",
    "        'scaler': StandardScaler,\n",
    "        'training_type': ModelTrainingType.BATCH,\n",
    "        'batch_size': 5_000_000\n",
    "    },\n",
    "    # SVC: {\n",
    "    #     'params': {\n",
    "    #         'kernel': ['rbf', 'poly', 'poly', 'poly', 'sigmoid'],\n",
    "    #         'degree': [3, 4, 5],\n",
    "    #         'C': [1, 10, 100, 1000],\n",
    "    #         'gamma': ['scale', 'auto']\n",
    "    #     },\n",
    "    #     'modeltype': SkLearnModel,\n",
    "    #     'scaler': StandardScaler\n",
    "    # },\n",
    "    # KNeighborsClassifier: {\n",
    "    #     'params': {\n",
    "    #         'n_neighbors': [5, 10, 15, 20],\n",
    "    #         'weights': ['uniform', 'distance'],\n",
    "    #         'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    #         'leaf_size': [10, 20, 30, 40, 50],\n",
    "    #         'p': [1, 2]\n",
    "    #     },\n",
    "    #     'modeltype': SkLearnModel,\n",
    "    #     'scaler': StandardScaler\n",
    "    # }\n",
    "}\n",
    "\n",
    "# define scaler\n",
    "scaler_type = StandardScaler\n",
    "pretrained_scalers = dict() # used to store trained scalers for later use\n",
    "\n",
    "# loop over all combinations and append it to the configurations list\n",
    "# if there are no hyperparams, just instantiate the model without params\n",
    "for model_type, hyperparams in models_and_hyperparams.items():\n",
    "    if len(hyperparams['params']) > 0: # if there are hyperparams, build a dict and pass it to the model as parameters\n",
    "        fx_param_names, fx_param_values = zip(*hyperparams['params'].items())\n",
    "        for cartesian_product_values in product(*fx_param_values):\n",
    "            hyperparam_dict = dict(zip(fx_param_names, cartesian_product_values))\n",
    "\n",
    "            # create or reuse the scaler specified in the models_and_hyperparams dictionary\n",
    "            # if hyperparams['scaler'] in pretrained_scalers:\n",
    "            #     print(f'Using pretrained scaler {hyperparams[\"scaler\"].__name__}')\n",
    "            #     scaler = pretrained_scalers[hyperparams['scaler']]\n",
    "            # else:\n",
    "            #     scaler = hyperparams['scaler']()\n",
    "            #     print(f'Start fitting scaler {hyperparams[\"scaler\"].__name__}')\n",
    "            #     for batch in tqdm(dataloader(batch_size=15_000_000)):\n",
    "            #         X = batch.drop(['wearable_on', 'awake', 'wakeup', 'onset'], axis=1)\n",
    "            #         X['series_id'] = X['series_id'].map(series_id_mapping['train'])\n",
    "            #         scaler.partial_fit(X)\n",
    "            #         del X\n",
    "            #         gc.collect()\n",
    "            #     # save the scaler for later use\n",
    "            #     pretrained_scalers[hyperparams['scaler']] = scaler\n",
    "\n",
    "            # create the model from the modeltype and the hyperparam_dict\n",
    "            m = hyperparams['modeltype'](model_type(**hyperparam_dict), \\\n",
    "                                        f'{model_type.__name__}-{\"-\".join([f\"{na}__{str(va)}\" for na, va in hyperparam_dict.items()])}'.lower(), \\\n",
    "                                        #pretrained_scalers[hyperparams['scaler']], \\\n",
    "                                        StandardScaler(), \\\n",
    "                                        hyperparam_dict)\n",
    "            \n",
    "\n",
    "#TODO: uncemment, standardscaler , not_scaled=True\n",
    "\n",
    "\n",
    "            \n",
    "            # init wandb\n",
    "            # start a new wandb run to track this script\n",
    "            #cfg = m._model_params.copy()\n",
    "            #cfg['model'] = m._model.__name__\n",
    "            #wandb.init(project=\"classic_models\", config=cfg)\n",
    "\n",
    "            # train model\n",
    "            if hyperparams['training_type'] == ModelTrainingType.BATCH:\n",
    "                print(f'Model will be traind in batches of {hyperparams[\"batch_size\"]} samples.')\n",
    "                print(f'Dataset contains {train_dataset_length} samples. {(rounds := train_dataset_length // hyperparams[\"batch_size\"])} batches will be used when fitting the model.')\n",
    "                if model_type == RandomForestClassifier:\n",
    "                    print(f'At the end {hyperparam_dict[\"n_estimators\"]} estimators will be fitted. That means, {hyperparam_dict[\"n_estimators\"]//rounds} estimators per batch.')\n",
    "                    m._model.n_estimators = 0 #set to 0. model will increase the number of estimators in each round\n",
    "\n",
    "            print(f'Start training model {m.identifier}')\n",
    "            for batch in tqdm(dataloader(batch_size=hyperparams['batch_size']) if hyperparams['training_type'] == ModelTrainingType.BATCH else [dataloader_full_dataset()]):\n",
    "                X = batch.drop(['wearable_on', 'awake', 'wakeup', 'onset'], axis=1)\n",
    "                X['series_id'] = X['series_id'].map(series_id_mapping['train'])\n",
    "                y = batch['wearable_on']\n",
    "                args = {}\n",
    "                if model_type == RandomForestClassifier: args['add_estimators'] = hyperparam_dict['n_estimators']//rounds\n",
    "                m.train(X, y, not_scaled=False, **args)\n",
    "                del X\n",
    "                del y\n",
    "                gc.collect()\n",
    "\n",
    "            #y_hat = configured_model.predict(X_test)\n",
    "\n",
    "            #  do the heuristic part...\n",
    "\n",
    "            #  evaluate model\n",
    "            print(f'Start evaluating model {m.identifier}')\n",
    "            validation = dataloader_full_dataset(validation=True)\n",
    "            validation['series_id'] = validation['series_id'].map(series_id_mapping['validation'])\n",
    "            validation_y = validation['wearable_on']\n",
    "            validation.drop(['wearable_on', 'awake', 'wakeup', 'onset'], axis=1, inplace=True)\n",
    "            validation_y_hat = m.predict(validation, not_scaled=False)\n",
    "            # this does the same as scoreFX(y, y_hat). It is wrapped in the models evaluate function.\n",
    "            # the model itself could also do the prediction if prepredicted is None\n",
    "            # then, the first argument of the evaluate function would be the X_validation data\n",
    "            score_value_average_precision_score = m.evaluate(None, validation_y, scoreFx=average_precision_score, not_scaled=False, prepredicted=validation_y_hat)\n",
    "            score_value_recall = m.evaluate(None, validation_y, scoreFx=recall_score, not_scaled=False, prepredicted=validation_y_hat)\n",
    "            score_value_precision = m.evaluate(None, validation_y, scoreFx=precision_score, not_scaled=False, prepredicted=validation_y_hat)\n",
    "            print(score_value_average_precision_score)\n",
    "            print(score_value_recall)\n",
    "            print(score_value_precision)\n",
    "            del validation, validation_y\n",
    "\n",
    "            #  save model\n",
    "            #m.save()\n",
    "\n",
    "\n",
    "            # delete model to free up memory\n",
    "            #del m\n",
    "\n",
    "            break\n",
    "\n",
    "            #wandb.finish()\n",
    "    else:\n",
    "        print(\"params in the dictionary cannot be empty. Use the standard values in the dictionary for the model\", model_type.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. add output of the **BEST** model 1 to train dataset -> [pred_wearable_on] -> must be saved to disk in batches!!!\n",
    "2. feed the new training to the second model\n",
    "   1. x of the second model is == ALL but X = batch.drop(['wearable_on', 'awake', 'wakeup', 'onset'], axis=1)\n",
    "   2. y of the second model is y = batch['awake']\n",
    "\n",
    "- Do not forget to map the series ID\n",
    "- ...\n",
    "\n",
    "\n",
    "1. the output of the **BEST** second model [pred_awake] must be passed through the heuristics fx alongside with.\n",
    "   1. the following datafields ['series_id', 'ALL TIME FIELDS', 'pred_awake, ??? others???] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aich",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
