{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to solve the kaggle competition \"Child Mind Institute - Detect Sleep States\"\n",
    "Link to the competition: https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states\n",
    "\n",
    "\n",
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in f:\\venv\\aich\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: plotly in f:\\venv\\aich\\lib\\site-packages (5.17.0)\n",
      "Requirement already satisfied: pandas in f:\\venv\\aich\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in f:\\venv\\aich\\lib\\site-packages (1.24.1)\n",
      "Requirement already satisfied: tqdm in f:\\venv\\aich\\lib\\site-packages (4.66.1)\n",
      "Requirement already satisfied: scikit-learn in f:\\venv\\aich\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: pyarrow in f:\\venv\\aich\\lib\\site-packages (13.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in f:\\venv\\aich\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in f:\\venv\\aich\\lib\\site-packages (from matplotlib) (0.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in f:\\venv\\aich\\lib\\site-packages (from matplotlib) (4.43.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in f:\\venv\\aich\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in f:\\venv\\aich\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in f:\\venv\\aich\\lib\\site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in f:\\venv\\aich\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in f:\\venv\\aich\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in f:\\venv\\aich\\lib\\site-packages (from plotly) (8.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\venv\\aich\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in f:\\venv\\aich\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: colorama in f:\\venv\\aich\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.5.0 in f:\\venv\\aich\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in f:\\venv\\aich\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in f:\\venv\\aich\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in f:\\venv\\aich\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib plotly pandas numpy tqdm scikit-learn pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from score import score\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score, precision_score, average_precision_score\n",
    "import wandb\n",
    "from abc import ABC, abstractmethod #, classmethod\n",
    "from math import ceil, floor\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pickle import dump, load\n",
    "from custom_enums import ModelTrainingType\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# wandb.login() requires you to get your API key from your account settings\n",
    "# open the weights and biases website https://wandb.ai/login and login to your account\n",
    "# then go to your account settings and copy the API key\n",
    "# paste it in the input box and hit enter\n",
    "\n",
    "#wandb.login() #TODO: uncomment this line to login to your account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start a new wandb run to track this script\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"my-awesome-project\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": 0.02,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"CIFAR-100\",\n",
    "#     \"epochs\": 10,\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to switch between different models from different libraries at a glance, we implement an interface called `IPipelineRequirements`. This allows us to make the pipleine even more robust and easier to extend upon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPipelineRequirements(ABC):\n",
    "    @abstractmethod\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def load(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model is the baseline model, which just takes the mean over all onset and wakeup times and tries to predict `onset` and `wakeup` events with the calculated time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(IPipelineRequirements):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "    def predict(self):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "    def save(self):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "    def load(self):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        raise NotImplementedError(\"Please Implement this method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = BaselineModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerous studies have concentrated on applications using `RandomForest`. The primary motivation for this preference is the model's inherent transparency in decision-making processes, which are readily identifiable in such models. Subsequent to the BaselineModel, efforts have been made to abstract models from the Scikit-learn library. Fortunately, the majority of models within their API exhibit consistent implementation patterns, facilitating their integration into the processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkLearnModel(IPipelineRequirements):\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        self.load(model_path)\n",
    "\n",
    "    def __init__(self, model, identifier, scaler=StandardScaler, sk_model_params=None):\n",
    "        self._model = model\n",
    "        self._scaler = scaler if not callable(scaler) else scaler() # if scaler is a classpointer, instantiate it\n",
    "        self.identifier = identifier\n",
    "        self._model_params = sk_model_params\n",
    "\n",
    "    def train(self, X, y, not_scaled=False, **kwargs):\n",
    "        if not_scaled:\n",
    "            X = self._scaler.transform(X)\n",
    "\n",
    "        # due to the big dataset we need to check wich model was instantiated and do some model\n",
    "        # specific stuff to enable us to train the model in batches\n",
    "        if isinstance(self._model, RandomForestClassifier):\n",
    "            new_estimators = kwargs['add_estimators'] if 'add_estimators' in kwargs else 50\n",
    "            if self._model.warm_start: self._model.n_estimators += new_estimators\n",
    "            #print(f'Current estimator increased to {self._model.n_estimators}, {new_estimators} added this round.')\n",
    "        # if isinstance(self._model, SVC):\n",
    "        #     pass\n",
    "\n",
    "        self._model.fit(X, y)\n",
    "\n",
    "    def predict(self, X, not_scaled=False):\n",
    "        if not self._model: raise ValueError('Please load or train a model first.')\n",
    "        if not_scaled:\n",
    "            if not self._scaler: raise ValueError('Please load or fit a scaler first.')\n",
    "            X = self._scaler.transform(X)\n",
    "        return self._model.predict(X)\n",
    "\n",
    "    def save(self):\n",
    "        try:\n",
    "            Path.mkdir(Path('models'), exist_ok=False)\n",
    "            with open(f'models/model_{self.identifier}.pkl', 'wb') as f:\n",
    "                dump(self._model, f)\n",
    "            with open(f'models/scaler_{self.identifier}.pkl', 'wb') as f:\n",
    "                dump(self._scaler, f)\n",
    "        except:\n",
    "            raise ValueError('Unable to save model and scaler.')\n",
    "\n",
    "    def load(self, filepath):\n",
    "        try:\n",
    "            # load model and scaler\n",
    "            if os.path.isfile(filepath):\n",
    "                print(f'Loading model from {filepath}')\n",
    "                with open(filepath, 'rb') as f:\n",
    "                    self._model = load(f)\n",
    "            scaler_path = f'{os.path.split(filepath)[0]}/scaler_{os.path.split(filepath)[1].split(\".\")[0].split(\"_\")[1]}.pkl'\n",
    "            if os.path.isfile(scaler_path):\n",
    "                print(f'Loading scaler from {scaler_path}')\n",
    "                with open(filepath, 'rb') as f:\n",
    "                    self._scaler = load(f)\n",
    "\n",
    "            # extract identifier from filename\n",
    "            self._identifier = filepath.split('_')[1].split('.')[0]\n",
    "        except (FileNotFoundError) as e:\n",
    "                print(f'File {e} not found')\n",
    "                raise ValueError('Filepath is not valid. Unable to load model and scaler.')\n",
    "        except (IndexError) as e:\n",
    "                print(f'The name of the file does not implement the convention \"<model|scaler>_<some identifier>\".')\n",
    "                raise ValueError('Filepath is not valid. Unable to load model and scaler.')\n",
    "        except (Exception) as e:\n",
    "            print(f'Something went wrong. {e}')\n",
    "            raise ValueError('Unknown Error.')\n",
    "\n",
    "    def evaluate(self, X, y, scoreFx=None, not_scaled=False, prepredicted=None):\n",
    "        if not scoreFx:\n",
    "            raise ValueError('Please provide a score function.')\n",
    "        if not self._model:\n",
    "            raise ValueError('Please load or train a model first.')\n",
    "        if not_scaled and prepredicted == None:\n",
    "            if not self._scaler: raise ValueError('Please load or fit a scaler first.')\n",
    "            X = self._scaler.transform(X)\n",
    "            \n",
    "        #TODO: Does score FX require an array of predictions or a single prediction?\n",
    "        #TODO: TEST PARAMS OF SCORE FX!!!!\n",
    "        return scoreFx(y, prepredicted if prepredicted is not None else self._model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristics method to get the right event under the constraints given by Child Mind Institue\n",
    "\n",
    "* A single sleep period must be at least 30 minutes in length\n",
    "* A single sleep period can be interrupted by bouts of activity that do not exceed 30 consecutive minutes\n",
    "* No sleep windows can be detected unless the watch is deemed to be worn for the duration (elaborated upon, below)\n",
    "* The longest sleep window during the night is the only one which is recorded\n",
    "* If no valid sleep window is identifiable, neither an onset nor a wakeup event is recorded for that night.\n",
    "* Sleep events do not need to straddle the day-line, and therefore there is no hard rule defining how many may occur within a given period. However, no more than one window should be assigned per night. For example, it is valid for an individual to have a sleep window from 01h00–06h00 and 19h00–23h30 in the same calendar day, though assigned to consecutive nights\n",
    "* There are roughly as many nights recorded for a series as there are 24-hour periods in that series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic_filter(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the training and the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "test",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\git\\AICH\\code\\classic_approach.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/git/AICH/code/classic_approach.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mraise\u001b[39;00m(\u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: test"
     ]
    }
   ],
   "source": [
    "raise(ValueError('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_TRAIN_DATA = '../data/train/'\n",
    "NEW_VALIDATION_DATA = '../data/val/'\n",
    "TRAIN_DATA = '../data/train_20231021'\n",
    "#TRAIN_DATA = '../data/train_20231021_20M'\n",
    "VALIDATION_DATA = '../data/validation_20231021'\n",
    "\n",
    "# figure out series id mapping\n",
    "if not 'series_id_mapping' in vars():\n",
    "    series_id_mapping = {'train': dict(), 'validation': dict()}\n",
    "    t = ds.dataset(NEW_TRAIN_DATA).to_table(columns=['series_id'])\n",
    "    #t = pq.ParquetDataset(TRAIN_DATA).read(columns=['series_id'])\n",
    "    for i, data in enumerate(t.to_pandas()['series_id'].unique()):\n",
    "        series_id_mapping['train'][data] = i\n",
    "    #v = pq.ParquetDataset(VALIDATION_DATA).read(columns=['series_id'])\n",
    "    v = ds.dataset(NEW_VALIDATION_DATA).to_table(columns=['series_id'])\n",
    "    for i, data in enumerate(v.to_pandas()['series_id'].unique()):\n",
    "        series_id_mapping['validation'][data] = i\n",
    "    del t, v\n",
    "    gc.collect()\n",
    "\n",
    "#train_dataset_length = pq.ParquetFile(TRAIN_DATA).metadata.num_rows\n",
    "train_dataset_length = ds.dataset(NEW_TRAIN_DATA).count_rows()\n",
    "validation_dataset_length = ds.dataset(NEW_VALIDATION_DATA).count_rows()\n",
    "\n",
    "def dataloader_full_dataset(validation=False):\n",
    "    return pd.read_parquet(VALIDATION_DATA if validation else TRAIN_DATA)\n",
    "\n",
    "def dataloader(validation=False, batch_size=5_000_000):\n",
    "    parquet_file = pq.ParquetFile(VALIDATION_DATA if validation else TRAIN_DATA)\n",
    "    for i in parquet_file.iter_batches(batch_size=batch_size):\n",
    "        yield i.to_pandas()\n",
    "\n",
    "def batched_dataloader(validation=False, batch_size=100_000):\n",
    "    dataset = ds.dataset(NEW_VALIDATION_DATA if validation else NEW_TRAIN_DATA)\n",
    "    for fragment in dataset.get_fragments():\n",
    "        batches = fragment.to_batches(batch_size=batch_size) # https://arrow.apache.org/docs/python/generated/pyarrow.dataset.Fragment.html#pyarrow.dataset.Fragment.to_batches\n",
    "        for batch in batches:\n",
    "            yield batch.to_pandas()\n",
    "            del batch\n",
    "        del fragment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will be traind in batches of 1000000 samples.\n",
      "Dataset contains 102937860 samples. 102 batches will be used when fitting the model.\n",
      "At the end 1000 estimators will be fitted. That means, 9 estimators per batch.\n",
      "Hyperparameter n_estimators will be adjusted to 1020 to fit 10.0 estimators per round for each 102 batches.\n",
      "Start training model randomforestclassifier-wrist-n_estimators__1000-max_depth__20-random_state__0-warm_start__true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "106it [1:12:41, 41.15s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start evaluating model randomforestclassifier-wrist-n_estimators__1000-max_depth__20-random_state__0-warm_start__true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [19:12, 44.32s/it]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8504913085074458\n",
      "0.9983862489386269\n",
      "0.8505018940867151\n",
      "Start training model randomforestclassifier-sleep-n_estimators__1000-max_depth__20-random_state__0-warm_start__true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/103 [03:11<5:25:37, 191.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/103 [05:30<4:30:49, 160.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (931099, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/103 [08:13<4:29:10, 161.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (992692, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/103 [10:59<4:29:20, 163.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 5/103 [14:01<4:38:01, 170.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (997082, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/103 [16:33<4:24:58, 163.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (980197, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/103 [19:13<4:20:15, 162.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/103 [22:08<4:23:32, 166.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 9/103 [24:31<4:09:21, 159.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (961716, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 10/103 [27:23<4:13:13, 163.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (999999, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/103 [30:14<4:13:57, 165.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (995610, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/103 [33:13<4:17:13, 169.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/103 [36:25<4:24:32, 176.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (916624, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 14/103 [38:34<4:00:18, 162.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 15/103 [41:21<4:00:09, 163.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/103 [44:24<4:05:26, 169.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (954275, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/103 [47:09<4:00:47, 168.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (989473, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 18/103 [49:18<3:41:42, 156.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 19/103 [52:24<3:51:23, 165.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 20/103 [55:28<3:56:22, 170.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (999396, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 21/103 [58:13<3:50:59, 169.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (986785, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 22/103 [1:00:46<3:41:51, 164.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 23/103 [1:03:38<3:42:10, 166.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (997776, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 24/103 [1:06:42<3:46:26, 171.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (927239, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 25/103 [1:08:57<3:28:51, 160.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (182672, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 26/103 [1:09:21<2:33:42, 119.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (970920, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 27/103 [1:12:18<2:53:26, 136.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (851034, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 28/103 [1:14:35<2:51:13, 136.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 29/103 [1:17:12<2:56:24, 143.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 30/103 [1:20:04<3:04:20, 151.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (994838, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 31/103 [1:22:37<3:02:35, 152.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 32/103 [1:25:15<3:01:57, 153.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (999932, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 33/103 [1:27:51<3:00:08, 154.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (987930, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 34/103 [1:30:17<2:54:52, 152.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (515458, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 35/103 [1:31:36<2:27:16, 129.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 36/103 [1:34:43<2:44:16, 147.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 37/103 [1:37:32<2:49:11, 153.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (984024, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 38/103 [1:39:52<2:42:08, 149.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (950140, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 39/103 [1:42:40<2:45:26, 155.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (995785, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 40/103 [1:44:49<2:34:46, 147.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (995542, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 41/103 [1:47:06<2:29:05, 144.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (974649, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 42/103 [1:49:52<2:33:09, 150.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (989541, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 43/103 [1:52:00<2:23:57, 143.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (999017, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 44/103 [1:54:36<2:25:01, 147.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (992761, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 45/103 [1:57:23<2:28:06, 153.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (941752, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 46/103 [1:59:48<2:23:27, 151.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 47/103 [2:02:34<2:25:04, 155.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 48/103 [2:05:31<2:28:21, 161.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (997298, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 49/103 [2:08:10<2:24:48, 160.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 50/103 [2:11:15<2:28:37, 168.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 51/103 [2:14:14<2:28:30, 171.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (296660, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 52/103 [2:14:48<1:50:41, 130.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 53/103 [2:17:03<1:49:44, 131.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 54/103 [2:19:29<1:51:08, 136.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 55/103 [2:22:28<1:58:59, 148.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (993107, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 56/103 [2:25:13<2:00:27, 153.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 57/103 [2:27:50<1:58:41, 154.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 58/103 [2:30:30<1:57:10, 156.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 59/103 [2:33:33<2:00:26, 164.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 60/103 [2:35:47<1:51:16, 155.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (999785, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 61/103 [2:37:55<1:42:55, 147.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (999998, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 62/103 [2:40:06<1:37:11, 142.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 63/103 [2:42:55<1:40:11, 150.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (969698, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 64/103 [2:45:27<1:38:02, 150.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 65/103 [2:48:04<1:36:40, 152.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 66/103 [2:50:09<1:28:59, 144.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (991113, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 67/103 [2:52:42<1:28:08, 146.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 68/103 [2:54:23<1:17:44, 133.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 69/103 [2:57:27<1:23:59, 148.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 70/103 [2:59:43<1:19:31, 144.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 71/103 [3:02:34<1:21:21, 152.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 72/103 [3:05:36<1:23:27, 161.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 73/103 [3:08:24<1:21:39, 163.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 74/103 [3:10:40<1:15:02, 155.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (999995, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 75/103 [3:12:02<1:02:09, 133.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (999994, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 76/103 [3:13:58<57:40, 128.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (998373, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 77/103 [3:16:44<1:00:26, 139.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (216920, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 78/103 [3:17:20<45:09, 108.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 79/103 [3:20:28<52:52, 132.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 80/103 [3:23:09<54:03, 141.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 81/103 [3:26:00<54:55, 149.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 82/103 [3:28:41<53:36, 153.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 83/103 [3:31:05<50:07, 150.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 84/103 [3:34:02<50:11, 158.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 85/103 [3:36:50<48:23, 161.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 86/103 [3:39:38<46:17, 163.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 87/103 [3:42:23<43:42, 163.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 88/103 [3:44:50<39:43, 158.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 89/103 [3:47:47<38:19, 164.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 90/103 [3:50:28<35:23, 163.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 91/103 [3:52:40<30:45, 153.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 92/103 [3:55:33<29:15, 159.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 93/103 [3:58:12<26:32, 159.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 94/103 [4:01:01<24:21, 162.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 95/103 [4:03:30<21:05, 158.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 96/103 [4:06:15<18:42, 160.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 97/103 [4:08:54<15:59, 159.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (995377, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 98/103 [4:10:59<12:26, 149.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 99/103 [4:13:13<09:39, 144.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (999867, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 100/103 [4:14:44<06:26, 128.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (999998, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 101/103 [4:17:35<04:42, 141.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 102/103 [4:20:31<02:31, 151.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [4:22:57<00:00, 149.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (588960, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [4:23:26, 113.63s/it]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1000000, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105it [4:26:32, 135.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (634040, 89)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "106it [4:28:15, 151.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start evaluating model randomforestclassifier-sleep-n_estimators__1000-max_depth__20-random_state__0-warm_start__true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- pred_worn\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\git\\AICH\\code\\classic_approach.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/git/AICH/code/classic_approach.ipynb#X26sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m validation_y \u001b[39m=\u001b[39m validation[\u001b[39m'\u001b[39m\u001b[39mawake\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/git/AICH/code/classic_approach.ipynb#X26sZmlsZQ%3D%3D?line=172'>173</a>\u001b[0m validation\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mwearable_on\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mawake\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/f%3A/git/AICH/code/classic_approach.ipynb#X26sZmlsZQ%3D%3D?line=173'>174</a>\u001b[0m validation_y_hat \u001b[39m=\u001b[39m m2\u001b[39m.\u001b[39;49mpredict(validation, not_scaled\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/git/AICH/code/classic_approach.ipynb#X26sZmlsZQ%3D%3D?line=174'>175</a>\u001b[0m \u001b[39m# this does the same as scoreFX(y, y_hat). It is wrapped in the models evaluate function.\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/git/AICH/code/classic_approach.ipynb#X26sZmlsZQ%3D%3D?line=175'>176</a>\u001b[0m \u001b[39m# the model itself could also do the prediction if prepredicted is None\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/git/AICH/code/classic_approach.ipynb#X26sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m \u001b[39m# then, the first argument of the evaluate function would be the X_validation data\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/f%3A/git/AICH/code/classic_approach.ipynb#X26sZmlsZQ%3D%3D?line=177'>178</a>\u001b[0m score_value_average_precision_score_m2\u001b[39m.\u001b[39mappend(m2\u001b[39m.\u001b[39mevaluate(\u001b[39mNone\u001b[39;00m, validation_y, scoreFx\u001b[39m=\u001b[39maverage_precision_score, not_scaled\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, prepredicted\u001b[39m=\u001b[39mvalidation_y_hat))\n",
      "\u001b[1;32mf:\\git\\AICH\\code\\classic_approach.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/git/AICH/code/classic_approach.ipynb#X26sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scaler: \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mPlease load or fit a scaler first.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/git/AICH/code/classic_approach.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scaler\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/git/AICH/code/classic_approach.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49mpredict(X)\n",
      "File \u001b[1;32mf:\\venv\\AICH\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    803\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 823\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    825\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    826\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mf:\\venv\\AICH\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    863\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    864\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    867\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    868\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mf:\\venv\\AICH\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    598\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 599\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    600\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mf:\\venv\\AICH\\Lib\\site-packages\\sklearn\\base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[0;32m    510\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    511\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[0;32m    517\u001b[0m ):\n\u001b[0;32m    518\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \n\u001b[0;32m    520\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    582\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    583\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    584\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    586\u001b[0m         )\n",
      "File \u001b[1;32mf:\\venv\\AICH\\Lib\\site-packages\\sklearn\\base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    503\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n\u001b[1;32m--> 507\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- pred_worn\n"
     ]
    }
   ],
   "source": [
    "# define all the combinations of models and features\n",
    "models_and_hyperparams = {\n",
    "    RandomForestClassifier: {\n",
    "        'params': {\n",
    "            'n_estimators': [1000, 1500, 2000],\n",
    "            'max_depth': [20, 40, 60, None],\n",
    "            'random_state': [0],\n",
    "            #'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "            'warm_start': [True]\n",
    "        },\n",
    "        'modeltype': SkLearnModel,\n",
    "        'scaler': StandardScaler,\n",
    "        'training_type': ModelTrainingType.BATCH,\n",
    "        'batch_size': 1_000_000\n",
    "    },\n",
    "    # SVC: {\n",
    "    #     'params': {\n",
    "    #         'kernel': ['rbf', 'poly', 'poly', 'poly', 'sigmoid'],\n",
    "    #         'degree': [3, 4, 5],\n",
    "    #         'C': [1, 10, 100, 1000],\n",
    "    #         'gamma': ['scale', 'auto']\n",
    "    #     },\n",
    "    #     'modeltype': SkLearnModel,\n",
    "    #     'scaler': StandardScaler\n",
    "    # },\n",
    "    # KNeighborsClassifier: {\n",
    "    #     'params': {\n",
    "    #         'n_neighbors': [5, 10, 15, 20],\n",
    "    #         'weights': ['uniform', 'distance'],\n",
    "    #         'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    #         'leaf_size': [10, 20, 30, 40, 50],\n",
    "    #         'p': [1, 2]\n",
    "    #     },\n",
    "    #     'modeltype': SkLearnModel,\n",
    "    #     'scaler': StandardScaler\n",
    "    # }\n",
    "}\n",
    "\n",
    "# define scaler\n",
    "scaler_type = StandardScaler\n",
    "pretrained_scalers = dict() # used to store trained scalers for later use\n",
    "\n",
    "# loop over all combinations and append it to the configurations list\n",
    "# if there are no hyperparams, just instantiate the model without params\n",
    "for model_type, hyperparams in models_and_hyperparams.items():\n",
    "    if len(hyperparams['params']) > 0: # if there are hyperparams, build a dict and pass it to the model as parameters\n",
    "        fx_param_names, fx_param_values = zip(*hyperparams['params'].items())\n",
    "        for cartesian_product_values in product(*fx_param_values):\n",
    "            hyperparam_dict = dict(zip(fx_param_names, cartesian_product_values))\n",
    "\n",
    "            # create or reuse the scaler specified in the models_and_hyperparams dictionary\n",
    "            # if hyperparams['scaler'] in pretrained_scalers:\n",
    "            #     print(f'Using pretrained scaler {hyperparams[\"scaler\"].__name__}')\n",
    "            #     scaler = pretrained_scalers[hyperparams['scaler']]\n",
    "            # else:\n",
    "            #     scaler = hyperparams['scaler']()\n",
    "            #     print(f'Start fitting scaler {hyperparams[\"scaler\"].__name__}')\n",
    "            #     for batch in tqdm(dataloader(batch_size=15_000_000)):\n",
    "            #         X = batch.drop(['wearable_on', 'awake', 'wakeup', 'onset'], axis=1)\n",
    "            #         X['series_id'] = X['series_id'].map(series_id_mapping['train'])\n",
    "            #         scaler.partial_fit(X)\n",
    "            #         del X\n",
    "            #         gc.collect()\n",
    "            #     # save the scaler for later use\n",
    "            #     pretrained_scalers[hyperparams['scaler']] = scaler\n",
    "\n",
    "            # create the model from the modeltype and the hyperparam_dict\n",
    "            m = hyperparams['modeltype'](model_type(**hyperparam_dict), \\\n",
    "                                        f'{model_type.__name__}-wrist-{\"-\".join([f\"{na}__{str(va)}\" for na, va in hyperparam_dict.items()])}'.lower(), \\\n",
    "                                        #pretrained_scalers[hyperparams['scaler']], \\\n",
    "                                        StandardScaler(), \\\n",
    "                                        hyperparam_dict)\n",
    "            m2 = hyperparams['modeltype'](model_type(**hyperparam_dict), \\\n",
    "                                        f'{model_type.__name__}-sleep-{\"-\".join([f\"{na}__{str(va)}\" for na, va in hyperparam_dict.items()])}'.lower(), \\\n",
    "                                        #pretrained_scalers[hyperparams['scaler']], \\\n",
    "                                        StandardScaler(), \\\n",
    "                                        hyperparam_dict)\n",
    "            \n",
    "\n",
    "#TODO: uncemment, standardscaler , not_scaled=True\n",
    "\n",
    "\n",
    "            \n",
    "            # init wandb\n",
    "            # start a new wandb run to track this script\n",
    "            #cfg = m._model_params.copy()\n",
    "            #cfg['model'] = m._model.__name__\n",
    "            #wandb.init(project=\"classic_models\", config=cfg)\n",
    "\n",
    "            # train model\n",
    "            rounds = 1\n",
    "            if hyperparams['training_type'] == ModelTrainingType.BATCH:\n",
    "                print(f'Model will be traind in batches of {hyperparams[\"batch_size\"]} samples.')\n",
    "                print(f'Dataset contains {train_dataset_length} samples. {(rounds := train_dataset_length // hyperparams[\"batch_size\"])} batches will be used when fitting the model.')\n",
    "                if model_type == RandomForestClassifier:\n",
    "                    print(f'At the end {hyperparam_dict[\"n_estimators\"]} estimators will be fitted. That means, {hyperparam_dict[\"n_estimators\"]//rounds} estimators per batch.')\n",
    "                    m._model.n_estimators = 0 #set to 0. model will increase the number of estimators in each round\n",
    "                    m2._model.n_estimators = 0 #set to 0. model will increase the number of estimators in each round\n",
    "                    # tune hyperparameter 'n_estimators' based on the number of batches\n",
    "                    attune_estimators_div = hyperparam_dict[\"n_estimators\"] / rounds\n",
    "                    attuned_estimators = (floor(attune_estimators_div) if attune_estimators_div -0.3 < floor(attune_estimators_div) else ceil(attune_estimators_div)) * rounds\n",
    "                    print(f'Hyperparameter n_estimators will be adjusted to {attuned_estimators} to fit {attuned_estimators / rounds} estimators per round for each {rounds} batches.')\n",
    "                    hyperparam_dict[\"n_estimators\"] = attuned_estimators\n",
    "\n",
    "            print(f'Start training model {m.identifier}')\n",
    "            for batch in tqdm(batched_dataloader(batch_size=hyperparams['batch_size']) if hyperparams['training_type'] == ModelTrainingType.BATCH else dataloader_full_dataset(), total=rounds+1):\n",
    "                #X = batch.drop(['wearable_on', 'awake', 'wakeup', 'onset'], axis=1)\n",
    "                X = batch.drop(['wearable_on', 'awake'], axis=1)\n",
    "                X['series_id'] = X['series_id'].map(series_id_mapping['train'])\n",
    "                y = batch['wearable_on']\n",
    "                args = {}\n",
    "                if model_type == RandomForestClassifier and hyperparams['training_type'] == ModelTrainingType.BATCH: args['add_estimators'] = hyperparam_dict['n_estimators']//rounds\n",
    "                m.train(X, y, not_scaled=False, **args)\n",
    "                del X\n",
    "                del y\n",
    "                gc.collect()\n",
    "            #y_hat = configured_model.predict(X_test)\n",
    "\n",
    "            #  do the heuristic part...\n",
    "\n",
    "            #  evaluate model\n",
    "            print(f'Start evaluating model {m.identifier}')\n",
    "            score_value_average_precision_score, score_value_recall, score_value_precision = [], [], []\n",
    "            for validation in tqdm(batched_dataloader(batch_size=hyperparams['batch_size'], validation=True) if hyperparams['training_type'] == ModelTrainingType.BATCH else dataloader_full_dataset(validation=True), total = validation_dataset_length // hyperparams[\"batch_size\"]):\n",
    "            #validation = batched_dataloader(validation=True)\n",
    "                validation['series_id'] = validation['series_id'].map(series_id_mapping['validation'])\n",
    "                validation_y = validation['wearable_on']\n",
    "                validation.drop(['wearable_on', 'awake'], axis=1, inplace=True)\n",
    "                validation_y_hat = m.predict(validation, not_scaled=False)\n",
    "                # this does the same as scoreFX(y, y_hat). It is wrapped in the models evaluate function.\n",
    "                # the model itself could also do the prediction if prepredicted is None\n",
    "                # then, the first argument of the evaluate function would be the X_validation data\n",
    "                score_value_average_precision_score.append(m.evaluate(None, validation_y, scoreFx=average_precision_score, not_scaled=False, prepredicted=validation_y_hat))\n",
    "                score_value_recall.append(m.evaluate(None, validation_y, scoreFx=recall_score, not_scaled=False, prepredicted=validation_y_hat))\n",
    "                score_value_precision.append(m.evaluate(None, validation_y, scoreFx=precision_score, not_scaled=False, prepredicted=validation_y_hat))\n",
    "            #print(score_value_average_precision_score)\n",
    "            #print(score_value_recall)\n",
    "            #print(score_value_precision)\n",
    "                del validation, validation_y\n",
    "\n",
    "            print(sum(score_value_average_precision_score) / len(score_value_average_precision_score))\n",
    "            print(sum(score_value_recall) / len(score_value_recall))\n",
    "            print(sum(score_value_precision) / len(score_value_precision))\n",
    "            #  save model\n",
    "            #m.save()\n",
    "\n",
    "            print(f'Start training model {m2.identifier}')\n",
    "            for batch in tqdm(batched_dataloader(batch_size=hyperparams['batch_size']) if hyperparams['training_type'] == ModelTrainingType.BATCH else dataloader_full_dataset(), total=rounds+1):\n",
    "                #X = batch.drop(['wearable_on', 'awake', 'wakeup', 'onset'], axis=1)\n",
    "                X = batch.drop(['wearable_on', 'awake'], axis=1)\n",
    "                X['series_id'] = X['series_id'].map(series_id_mapping['train'])\n",
    "                y = batch['awake']\n",
    "                args = {}\n",
    "                if model_type == RandomForestClassifier and hyperparams['training_type'] == ModelTrainingType.BATCH: args['add_estimators'] = hyperparam_dict['n_estimators']//rounds\n",
    "                worn_y_hat = m.predict(X, not_scaled=False)\n",
    "                # add worn_y_hat as new column to X\n",
    "                X['pred_worn'] = worn_y_hat\n",
    "                # filter out all rows where worn_y_hat is 0\n",
    "                X = X[X['pred_worn'] == 1]\n",
    "                y = y[y.index.isin(X.index)]\n",
    "                m2.train(X, y, not_scaled=False, **args)\n",
    "                del X\n",
    "                del y\n",
    "                gc.collect()\n",
    "\n",
    "            print(f'Start evaluating model {m2.identifier}')\n",
    "            score_value_average_precision_score_m2, score_value_recall_m2, score_value_precision_m2 = [], [], []\n",
    "            for validation in tqdm(batched_dataloader(batch_size=hyperparams['batch_size'], validation=True) if hyperparams['training_type'] == ModelTrainingType.BATCH else dataloader_full_dataset(validation=True), total = validation_dataset_length // hyperparams[\"batch_size\"]):\n",
    "            #validation = batched_dataloader(validation=True)\n",
    "                validation['series_id'] = validation['series_id'].map(series_id_mapping['validation'])\n",
    "                validation_y = validation['awake']\n",
    "                validation.drop(['wearable_on', 'awake'], axis=1, inplace=True)\n",
    "                worn_y_hat = m.predict(validation, not_scaled=False)\n",
    "                validation['pred_worn'] = worn_y_hat\n",
    "                validation = validation[validation['pred_worn'] == 1]\n",
    "                validation_y = validation_y[validation_y.index.isin(validation.index)]\n",
    "                validation_y_hat = m2.predict(validation, not_scaled=False)\n",
    "                # this does the same as scoreFX(y, y_hat). It is wrapped in the models evaluate function.\n",
    "                # the model itself could also do the prediction if prepredicted is None\n",
    "                # then, the first argument of the evaluate function would be the X_validation data\n",
    "                score_value_average_precision_score_m2.append(m2.evaluate(None, validation_y, scoreFx=average_precision_score, not_scaled=False, prepredicted=validation_y_hat))\n",
    "                score_value_recall_m2.append(m2.evaluate(None, validation_y, scoreFx=recall_score, not_scaled=False, prepredicted=validation_y_hat))\n",
    "                score_value_precision_m2.append(m2.evaluate(None, validation_y, scoreFx=precision_score, not_scaled=False, prepredicted=validation_y_hat))\n",
    "            #print(score_value_average_precision_score)\n",
    "            #print(score_value_recall)\n",
    "            #print(score_value_precision)\n",
    "                del validation, validation_y\n",
    "\n",
    "            print(sum(score_value_average_precision_score_m2) / len(score_value_average_precision_score_m2))\n",
    "            print(sum(score_value_recall_m2) / len(score_value_recall_m2))\n",
    "            print(sum(score_value_precision_m2) / len(score_value_precision_m2))\n",
    "            # delete model to free up memory\n",
    "            #del m\n",
    "\n",
    "            break\n",
    "\n",
    "            #wandb.finish()\n",
    "    else:\n",
    "        print(\"params in the dictionary cannot be empty. Use the standard values in the dictionary for the model\", model_type.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start evaluating model randomforestclassifier-sleep-n_estimators__1000-max_depth__20-random_state__0-warm_start__true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [51:10, 118.11s/it]                        \n"
     ]
    }
   ],
   "source": [
    "print(f'Start evaluating model {m2.identifier}')\n",
    "score_value_average_precision_score_m2, score_value_recall_m2, score_value_precision_m2 = [], [], []\n",
    "for validation in tqdm(batched_dataloader(batch_size=hyperparams['batch_size'], validation=True) if hyperparams['training_type'] == ModelTrainingType.BATCH else dataloader_full_dataset(validation=True), total = validation_dataset_length // hyperparams[\"batch_size\"]):\n",
    "#validation = batched_dataloader(validation=True)\n",
    "    validation['series_id'] = validation['series_id'].map(series_id_mapping['validation'])\n",
    "    validation_y = validation['awake']\n",
    "    validation.drop(['wearable_on', 'awake'], axis=1, inplace=True)\n",
    "    worn_y_hat = m.predict(validation, not_scaled=False)\n",
    "    validation['pred_worn'] = worn_y_hat\n",
    "    validation = validation[validation['pred_worn'] == 1]\n",
    "    validation_y = validation_y[validation_y.index.isin(validation.index)]\n",
    "    validation_y_hat = m2.predict(validation, not_scaled=False)\n",
    "    # this does the same as scoreFX(y, y_hat). It is wrapped in the models evaluate function.\n",
    "    # the model itself could also do the prediction if prepredicted is None\n",
    "    # then, the first argument of the evaluate function would be the X_validation data\n",
    "    score_value_average_precision_score_m2.append(m2.evaluate(None, validation_y, scoreFx=average_precision_score, not_scaled=False, prepredicted=validation_y_hat))\n",
    "    score_value_recall_m2.append(m2.evaluate(None, validation_y, scoreFx=recall_score, not_scaled=False, prepredicted=validation_y_hat))\n",
    "    score_value_precision_m2.append(m2.evaluate(None, validation_y, scoreFx=precision_score, not_scaled=False, prepredicted=validation_y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9607095567837105\n",
      "0.9281085846082481\n",
      "0.9731355200195849\n"
     ]
    }
   ],
   "source": [
    "print(sum(score_value_average_precision_score_m2) / len(score_value_average_precision_score_m2))\n",
    "print(sum(score_value_recall_m2) / len(score_value_recall_m2))\n",
    "print(sum(score_value_precision_m2) / len(score_value_precision_m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/AAAA.pkl', 'wb') as f:\n",
    "    dump(m._model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/BBBB.pkl', 'wb') as f:\n",
    "    dump(m2._model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26062016, 0.00587829, 0.0036312 , 0.0067284 , 0.00313009,\n",
       "       0.0023635 , 0.13000739, 0.08961576, 0.03968891, 0.00650785,\n",
       "       0.004985  , 0.00574397, 0.00601681, 0.00674708, 0.00916001,\n",
       "       0.00645703, 0.01008137, 0.00771209, 0.00460338, 0.00187635,\n",
       "       0.00212878, 0.00584396, 0.00304738, 0.00260252, 0.0102062 ,\n",
       "       0.00257583, 0.01008914, 0.00239926, 0.0018233 , 0.0074098 ,\n",
       "       0.01305531, 0.0105764 , 0.01563973, 0.01248217, 0.00622891,\n",
       "       0.01374397, 0.01110173, 0.00869639, 0.00325989, 0.00711063,\n",
       "       0.00839432, 0.0102059 , 0.00896969, 0.01967453, 0.00406012,\n",
       "       0.0162956 , 0.00609977, 0.00351079, 0.00349858, 0.00432328,\n",
       "       0.00430827, 0.00365324, 0.00467349, 0.00531373, 0.00296852,\n",
       "       0.00231341, 0.00493366, 0.00602081, 0.00053684, 0.00281932,\n",
       "       0.00216382, 0.00211915, 0.00397052, 0.00743335, 0.00120637,\n",
       "       0.00171118, 0.00238241, 0.00091997, 0.00588115, 0.0042996 ,\n",
       "       0.00563069, 0.00923931, 0.00519159, 0.00797593, 0.00543656,\n",
       "       0.00662034, 0.00573557, 0.00083395, 0.00400749, 0.00481804,\n",
       "       0.00367338, 0.00408961, 0.00627604, 0.00367186, 0.00798897,\n",
       "       0.00090333, 0.00166999])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m._model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = batched_dataloader(validation=True, batch_size=400_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = next(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg.drop(['wearable_on', 'awake'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg['pred_worn'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['series_id', 'step', 'anglez', 'enmo', 'hour', 'minute', 'seconds',\n",
       "       'day', 'month', 'year', 'anglez_abs', 'anglez_rolling_mean_12',\n",
       "       'anglez_rolling_sum_12', 'anglez_rolling_max_12',\n",
       "       'anglez_rolling_min_12', 'anglez_rolling_std_12',\n",
       "       'anglez_rolling_median_12', 'anglez_rolling_variance_12',\n",
       "       'anglez_rolling_25th_percentile_12',\n",
       "       'anglez_rolling_75th_percentile_12', 'anglez_diff_12',\n",
       "       'anglez_diff_rolling_mean_12', 'anglez_diff_rolling_sum_12',\n",
       "       'anglez_diff_rolling_max_12', 'anglez_diff_rolling_min_12',\n",
       "       'anglez_diff_rolling_std_12', 'anglez_diff_rolling_median_12',\n",
       "       'anglez_diff_rolling_variance_12',\n",
       "       'anglez_diff_rolling_25th_percentile_12',\n",
       "       'anglez_diff_rolling_75th_percentile_12', 'anglez_rolling_mean_60',\n",
       "       'anglez_rolling_sum_60', 'anglez_rolling_max_60',\n",
       "       'anglez_rolling_min_60', 'anglez_rolling_std_60',\n",
       "       'anglez_rolling_median_60', 'anglez_rolling_variance_60',\n",
       "       'anglez_rolling_25th_percentile_60',\n",
       "       'anglez_rolling_75th_percentile_60', 'anglez_diff_60',\n",
       "       'anglez_diff_rolling_mean_60', 'anglez_diff_rolling_sum_60',\n",
       "       'anglez_diff_rolling_max_60', 'anglez_diff_rolling_min_60',\n",
       "       'anglez_diff_rolling_std_60', 'anglez_diff_rolling_median_60',\n",
       "       'anglez_diff_rolling_variance_60',\n",
       "       'anglez_diff_rolling_25th_percentile_60',\n",
       "       'anglez_diff_rolling_75th_percentile_60', 'enmo_abs',\n",
       "       'enmo_rolling_mean_12', 'enmo_rolling_sum_12', 'enmo_rolling_max_12',\n",
       "       'enmo_rolling_min_12', 'enmo_rolling_std_12', 'enmo_rolling_median_12',\n",
       "       'enmo_rolling_variance_12', 'enmo_rolling_25th_percentile_12',\n",
       "       'enmo_rolling_75th_percentile_12', 'enmo_diff_12',\n",
       "       'enmo_diff_rolling_mean_12', 'enmo_diff_rolling_sum_12',\n",
       "       'enmo_diff_rolling_max_12', 'enmo_diff_rolling_min_12',\n",
       "       'enmo_diff_rolling_std_12', 'enmo_diff_rolling_median_12',\n",
       "       'enmo_diff_rolling_variance_12', 'enmo_diff_rolling_25th_percentile_12',\n",
       "       'enmo_diff_rolling_75th_percentile_12', 'enmo_rolling_mean_60',\n",
       "       'enmo_rolling_sum_60', 'enmo_rolling_max_60', 'enmo_rolling_min_60',\n",
       "       'enmo_rolling_std_60', 'enmo_rolling_median_60',\n",
       "       'enmo_rolling_variance_60', 'enmo_rolling_25th_percentile_60',\n",
       "       'enmo_rolling_75th_percentile_60', 'enmo_diff_60',\n",
       "       'enmo_diff_rolling_mean_60', 'enmo_diff_rolling_sum_60',\n",
       "       'enmo_diff_rolling_max_60', 'enmo_diff_rolling_min_60',\n",
       "       'enmo_diff_rolling_std_60', 'enmo_diff_rolling_median_60',\n",
       "       'enmo_diff_rolling_variance_60', 'enmo_diff_rolling_25th_percentile_60',\n",
       "       'enmo_diff_rolling_75th_percentile_60', 'pred_worn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('step', 0.2606201637780376),\n",
       " ('day', 0.13000738739185558),\n",
       " ('month', 0.08961576019141494),\n",
       " ('year', 0.0396889064974704),\n",
       " ('anglez_diff_rolling_std_60', 0.01967452775656659),\n",
       " ('anglez_diff_rolling_variance_60', 0.016295595479441097),\n",
       " ('anglez_rolling_min_60', 0.015639734409586502),\n",
       " ('anglez_rolling_variance_60', 0.013743969730654821),\n",
       " ('anglez_rolling_sum_60', 0.01305531394729148),\n",
       " ('anglez_rolling_std_60', 0.012482167698995373),\n",
       " ('anglez_rolling_25th_percentile_60', 0.011101729729531409),\n",
       " ('anglez_rolling_max_60', 0.010576399763930622),\n",
       " ('anglez_diff_rolling_std_12', 0.010206195539808283),\n",
       " ('anglez_diff_rolling_max_60', 0.010205901807059478),\n",
       " ('anglez_diff_rolling_variance_12', 0.01008914374048936),\n",
       " ('anglez_rolling_variance_12', 0.010081370058817232),\n",
       " ('enmo_rolling_min_60', 0.009239309666437786),\n",
       " ('anglez_rolling_std_12', 0.009160005279233812),\n",
       " ('anglez_diff_rolling_min_60', 0.008969692245192491),\n",
       " ('anglez_rolling_75th_percentile_60', 0.008696389961548387),\n",
       " ('anglez_diff_rolling_sum_60', 0.00839432128087844),\n",
       " ('enmo_diff_rolling_variance_60', 0.007988969825986495),\n",
       " ('enmo_rolling_median_60', 0.007975928961920656),\n",
       " ('anglez_rolling_25th_percentile_12', 0.007712093505248621),\n",
       " ('enmo_diff_rolling_std_12', 0.007433346293469274),\n",
       " ('anglez_rolling_mean_60', 0.007409803016417404),\n",
       " ('anglez_diff_rolling_mean_60', 0.007110625438676514),\n",
       " ('anglez_rolling_min_12', 0.006747075233154746),\n",
       " ('hour', 0.006728398266677261),\n",
       " ('enmo_rolling_25th_percentile_60', 0.006620342706315131),\n",
       " ('anglez_abs', 0.006507851903051597),\n",
       " ('anglez_rolling_median_12', 0.006457034736477353),\n",
       " ('enmo_diff_rolling_std_60', 0.006276038596500295),\n",
       " ('anglez_rolling_median_60', 0.00622891396561268),\n",
       " ('anglez_diff_rolling_25th_percentile_60', 0.006099765483610029),\n",
       " ('enmo_rolling_75th_percentile_12', 0.006020812410946578),\n",
       " ('anglez_rolling_max_12', 0.006016811084577596),\n",
       " ('enmo_rolling_mean_60', 0.0058811542234062705),\n",
       " ('anglez', 0.005878289715050448),\n",
       " ('anglez_diff_rolling_sum_12', 0.005843962257283623),\n",
       " ('anglez_rolling_sum_12', 0.0057439707352293645),\n",
       " ('enmo_rolling_75th_percentile_60', 0.0057355653715918985),\n",
       " ('enmo_rolling_max_60', 0.005630694133399703),\n",
       " ('enmo_rolling_variance_60', 0.005436558366912023),\n",
       " ('enmo_rolling_std_12', 0.005313732814729802),\n",
       " ('enmo_rolling_std_60', 0.005191588423531909),\n",
       " ('anglez_rolling_mean_12', 0.004985002759081966),\n",
       " ('enmo_rolling_25th_percentile_12', 0.004933656513841403),\n",
       " ('enmo_diff_rolling_sum_60', 0.004818039625637577),\n",
       " ('enmo_rolling_min_12', 0.00467349156140302),\n",
       " ('anglez_rolling_75th_percentile_12', 0.0046033798465172126),\n",
       " ('enmo_rolling_mean_12', 0.004323283726918373),\n",
       " ('enmo_rolling_sum_12', 0.00430827426657198),\n",
       " ('enmo_rolling_sum_60', 0.004299598987898045),\n",
       " ('enmo_diff_rolling_min_60', 0.004089608198026151),\n",
       " ('anglez_diff_rolling_median_60', 0.004060122898654543),\n",
       " ('enmo_diff_rolling_mean_60', 0.004007494327302602),\n",
       " ('enmo_diff_rolling_min_12', 0.003970515412540217),\n",
       " ('enmo_diff_rolling_max_60', 0.0036733803944454155),\n",
       " ('enmo_diff_rolling_median_60', 0.0036718585289765775),\n",
       " ('enmo_rolling_max_12', 0.0036532426053854086),\n",
       " ('enmo', 0.003631198284876963),\n",
       " ('anglez_diff_rolling_75th_percentile_60', 0.003510791710648037),\n",
       " ('enmo_abs', 0.003498581022005542),\n",
       " ('anglez_diff_60', 0.0032598938914043018),\n",
       " ('minute', 0.003130087835625744),\n",
       " ('anglez_diff_rolling_max_12', 0.0030473793409025395),\n",
       " ('enmo_rolling_median_12', 0.002968517028472293),\n",
       " ('enmo_diff_rolling_mean_12', 0.0028193230097995335),\n",
       " ('anglez_diff_rolling_min_12', 0.0026025222807976823),\n",
       " ('anglez_diff_rolling_median_12', 0.0025758254344723326),\n",
       " ('anglez_diff_rolling_25th_percentile_12', 0.002399258097186001),\n",
       " ('enmo_diff_rolling_25th_percentile_12', 0.002382413735690453),\n",
       " ('seconds', 0.0023635025388566476),\n",
       " ('enmo_rolling_variance_12', 0.0023134077833658947),\n",
       " ('enmo_diff_rolling_sum_12', 0.0021638222922470435),\n",
       " ('anglez_diff_rolling_mean_12', 0.00212877771439563),\n",
       " ('enmo_diff_rolling_max_12', 0.0021191490665574157),\n",
       " ('anglez_diff_12', 0.0018763488547791198),\n",
       " ('anglez_diff_rolling_75th_percentile_12', 0.0018233032802323532),\n",
       " ('enmo_diff_rolling_variance_12', 0.001711180703197423),\n",
       " ('enmo_diff_rolling_75th_percentile_60', 0.0016699873204278257),\n",
       " ('enmo_diff_rolling_median_12', 0.0012063719464015165),\n",
       " ('enmo_diff_rolling_75th_percentile_12', 0.0009199713872931022),\n",
       " ('enmo_diff_rolling_25th_percentile_60', 0.0009033268530061689),\n",
       " ('enmo_diff_60', 0.0008339529109635842),\n",
       " ('enmo_diff_12', 0.0005368425991755161)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(fg.columns, m._model.feature_importances_)), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. add output of the **BEST** model 1 to train dataset -> [pred_wearable_on] -> must be saved to disk in batches!!!\n",
    "2. feed the new training to the second model\n",
    "   1. x of the second model is == ALL but X = batch.drop(['wearable_on', 'awake', 'wakeup', 'onset'], axis=1)\n",
    "   2. y of the second model is y = batch['awake']\n",
    "\n",
    "- Do not forget to map the series ID\n",
    "- All values where pred_wearable_on == 0 must be dropped from the traning set for the second model...\n",
    "  this can be done by adding a filter to the parquet reader like so:\n",
    "  ```python\n",
    "  table = pq.read_table(\"example.parquet\",\n",
    "                      columns=[\"col1\"],\n",
    "                      filters=[\n",
    "                          (\"col1\", \">\", 5),\n",
    "                          (\"col1\", \"<\", 10),\n",
    "                      ])\n",
    "  ```\n",
    "\n",
    "\n",
    "1. the output of the **BEST** second model [pred_awake] must be passed through the heuristics fx alongside with.\n",
    "   1. the following datafields ['series_id', 'ALL TIME FIELDS', 'pred_awake, ??? others???] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplication of first pipeline\n",
    "\n",
    "This pipelines purpos is to train the second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all the combinations of models and features\n",
    "models_and_hyperparams = {\n",
    "    RandomForestClassifier: {\n",
    "        'params': {\n",
    "            'n_estimators': [200, 300, 400],\n",
    "            'max_depth': [10, 20, 30, None],\n",
    "            'random_state': [0],\n",
    "            'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "            'warm_start': [True]\n",
    "        },\n",
    "        'modeltype': SkLearnModel,\n",
    "        'scaler': StandardScaler,\n",
    "        'training_type': ModelTrainingType.BATCH,\n",
    "        'batch_size': 5_000_000\n",
    "    }\n",
    "}\n",
    "\n",
    "# define scaler\n",
    "scaler_type = StandardScaler\n",
    "pretrained_scalers = dict() # used to store trained scalers for later use\n",
    "\n",
    "# loop over all combinations and append it to the configurations list\n",
    "# if there are no hyperparams, just instantiate the model without params\n",
    "for model_type, hyperparams in models_and_hyperparams.items():\n",
    "    if len(hyperparams['params']) > 0: # if there are hyperparams, build a dict and pass it to the model as parameters\n",
    "        fx_param_names, fx_param_values = zip(*hyperparams['params'].items())\n",
    "        for cartesian_product_values in product(*fx_param_values):\n",
    "            hyperparam_dict = dict(zip(fx_param_names, cartesian_product_values))\n",
    "\n",
    "            # create or reuse the scaler specified in the models_and_hyperparams dictionary\n",
    "            # if hyperparams['scaler'] in pretrained_scalers:\n",
    "            #     print(f'Using pretrained scaler {hyperparams[\"scaler\"].__name__}')\n",
    "            #     scaler = pretrained_scalers[hyperparams['scaler']]\n",
    "            # else:\n",
    "            #     scaler = hyperparams['scaler']()\n",
    "            #     print(f'Start fitting scaler {hyperparams[\"scaler\"].__name__}')\n",
    "            #     for batch in tqdm(dataloader(batch_size=15_000_000)):\n",
    "            #         X = batch.drop(['wearable_on', 'awake', 'wakeup', 'onset'], axis=1)\n",
    "            #         X['series_id'] = X['series_id'].map(series_id_mapping['train'])\n",
    "            #         scaler.partial_fit(X)\n",
    "            #         del X\n",
    "            #         gc.collect()\n",
    "            #     # save the scaler for later use\n",
    "            #     pretrained_scalers[hyperparams['scaler']] = scaler\n",
    "\n",
    "            # create the model from the modeltype and the hyperparam_dict\n",
    "            m = hyperparams['modeltype'](model_type(**hyperparam_dict), \\\n",
    "                                        f'{model_type.__name__}-{\"-\".join([f\"{na}__{str(va)}\" for na, va in hyperparam_dict.items()])}'.lower(), \\\n",
    "                                        #pretrained_scalers[hyperparams['scaler']], \\\n",
    "                                        StandardScaler(), \\\n",
    "                                        hyperparam_dict)\n",
    "            \n",
    "\n",
    "#TODO: uncemment, standardscaler , not_scaled=True\n",
    "\n",
    "\n",
    "            \n",
    "            # init wandb\n",
    "            # start a new wandb run to track this script\n",
    "            #cfg = m._model_params.copy()\n",
    "            #cfg['model'] = m._model.__name__\n",
    "            #wandb.init(project=\"classic_models\", config=cfg)\n",
    "\n",
    "            # train model\n",
    "            if hyperparams['training_type'] == ModelTrainingType.BATCH:\n",
    "                print(f'Model will be traind in batches of {hyperparams[\"batch_size\"]} samples.')\n",
    "                print(f'Dataset contains {train_dataset_length} samples. {(rounds := train_dataset_length // hyperparams[\"batch_size\"])} batches will be used when fitting the model.')\n",
    "                if model_type == RandomForestClassifier:\n",
    "                    print(f'At the end {hyperparam_dict[\"n_estimators\"]} estimators will be fitted. That means, {hyperparam_dict[\"n_estimators\"]//rounds} estimators per batch.')\n",
    "                    m._model.n_estimators = 0 #set to 0. model will increase the number of estimators in each round\n",
    "\n",
    "            print(f'Start training model {m.identifier}')\n",
    "            for batch in tqdm(dataloader(batch_size=hyperparams['batch_size']) if hyperparams['training_type'] == ModelTrainingType.BATCH else [dataloader_full_dataset()]):\n",
    "                X = batch.drop(['wearable_on', 'awake', 'wakeup', 'onset'], axis=1)\n",
    "                X['series_id'] = X['series_id'].map(series_id_mapping['train'])\n",
    "                y = batch['awake']\n",
    "                args = {}\n",
    "                if model_type == RandomForestClassifier: args['add_estimators'] = hyperparam_dict['n_estimators']//rounds\n",
    "                m.train(X, y, not_scaled=False, **args)\n",
    "                del X\n",
    "                del y\n",
    "                gc.collect()\n",
    "\n",
    "            #y_hat = configured_model.predict(X_test)\n",
    "\n",
    "            #  do the heuristic part...\n",
    "\n",
    "            #  evaluate model\n",
    "            print(f'Start evaluating model {m.identifier}')\n",
    "            validation = dataloader_full_dataset(validation=True)\n",
    "            validation['series_id'] = validation['series_id'].map(series_id_mapping['validation'])\n",
    "            validation_y = validation['awake']\n",
    "            validation.drop(['wearable_on', 'awake', 'wakeup', 'onset'], axis=1, inplace=True)\n",
    "            validation_y_hat = m.predict(validation, not_scaled=False)\n",
    "            # this does the same as scoreFX(y, y_hat). It is wrapped in the models evaluate function.\n",
    "            # the model itself could also do the prediction if prepredicted is None\n",
    "            # then, the first argument of the evaluate function would be the X_validation data\n",
    "            score_value_average_precision_score = m.evaluate(None, validation_y, scoreFx=average_precision_score, not_scaled=False, prepredicted=validation_y_hat)\n",
    "            score_value_recall = m.evaluate(None, validation_y, scoreFx=recall_score, not_scaled=False, prepredicted=validation_y_hat)\n",
    "            score_value_precision = m.evaluate(None, validation_y, scoreFx=precision_score, not_scaled=False, prepredicted=validation_y_hat)\n",
    "            print(score_value_average_precision_score)\n",
    "            print(score_value_recall)\n",
    "            print(score_value_precision)\n",
    "            del validation, validation_y\n",
    "\n",
    "            #  save model\n",
    "            #m.save()\n",
    "\n",
    "\n",
    "            # delete model to free up memory\n",
    "            #del m\n",
    "\n",
    "            break\n",
    "\n",
    "            #wandb.finish()\n",
    "    else:\n",
    "        print(\"params in the dictionary cannot be empty. Use the standard values in the dictionary for the model\", model_type.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: https://arrow.apache.org/cookbook/py/io.html#id11\n",
    "# for splitted files "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aich",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
