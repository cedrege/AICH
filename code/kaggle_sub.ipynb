{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import ceil, floor\n",
    "import os\n",
    "from pickle import dump, load\n",
    "import pandas as pd\n",
    "import pyarrow.dataset as ds\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_step_on_train_events_when_nan(train_events): \n",
    "    last_value = 0\n",
    "\n",
    "    for index, data in train_events.iterrows():\n",
    "        if pd.isnull(data['step']):\n",
    "            train_events.at[index, 'step'] = last_value + 1\n",
    "        \n",
    "        last_value = train_events.at[index, 'step']\n",
    "\n",
    "    train_events[\"step\"]  = train_events[\"step\"].astype(\"int\")\n",
    "    \n",
    "    return train_events\n",
    "\n",
    "def engineer_awake_on_train_events(train_events):\n",
    "    train_events[\"awake\"] = train_events[\"event\"].replace({\"onset\":1,\"wakeup\":0})\n",
    "    \n",
    "    train_events[\"onset\"] = train_events[\"event\"].replace({\"onset\":1,\"wakeup\":0})\n",
    "    train_events[\"onset\"].fillna(0)\n",
    "    \n",
    "    train_events[\"wakeup\"] = train_events[\"event\"].replace({\"onset\":0,\"wakeup\":1})\n",
    "    train_events[\"wakeup\"].fillna(0)\n",
    "    \n",
    "    return train_events\n",
    "\n",
    "def engineer_wearable_on_on_train_events(train_events):\n",
    "    train_events['wearable_on'] = 1\n",
    "    train_events.loc[train_events['step'].isna(), 'wearable_on'] = 0    \n",
    "\n",
    "    return train_events\n",
    "\n",
    "def engineer_awake_on_train(train):\n",
    "    # final section:\n",
    "    # train_events.groupby('series_id').tail(1)[\"event\"].unique()\n",
    "    # Result: the last event is always a \"wakeup\n",
    "    train[\"awake\"].bfill(axis ='rows', inplace=True)\n",
    "    train['awake'].fillna(1, inplace=True) # awake\n",
    "    train[\"awake\"] = train[\"awake\"].astype(\"int\")\n",
    "    \n",
    "    return train\n",
    "\n",
    "def engineer_wearable_on_on_train(train):\n",
    "    train[\"wearable_on\"].bfill(inplace=True)\n",
    "    train[\"wearable_on\"].ffill(inplace=True)\n",
    "\n",
    "    return train\n",
    "\n",
    "def split_timestamp_on_train(train):\n",
    "    train['timestamp'] = train['timestamp'].str[:-5]\n",
    "\n",
    "    train['hour'] = pd.to_numeric(train['timestamp'].str[-8:-6])\n",
    "    train['minute'] = pd.to_numeric(train['timestamp'].str[-5:-3])\n",
    "    train['seconds'] = pd.to_numeric(train['timestamp'].str[-2:])\n",
    "\n",
    "    train['day'] = pd.to_numeric(train['timestamp'].str[-11:-9])\n",
    "    train['month'] = pd.to_numeric(train['timestamp'].str[-14:-12])\n",
    "    train['year'] = pd.to_numeric(train['timestamp'].str[-20:-15])\n",
    "\n",
    "    train.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "    return train\n",
    "\n",
    "def engineer_anglez_features(train, periods):\n",
    "    return engineer_sensor_features(train, periods, 'anglez')\n",
    "\n",
    "def engineer_enmo_features(train, periods):\n",
    "    return engineer_sensor_features(train, periods, 'enmo')\n",
    "\n",
    "def engineer_sensor_features(train, periods, feature_name):\n",
    "    train[f\"{feature_name}_abs\"] = abs(train[feature_name]).astype(\"float32\")\n",
    "\n",
    "    for period in periods:\n",
    "        train = engineer_sensor_periods_features(train, period, feature_name)\n",
    "\n",
    "    return train\n",
    "\n",
    "def engineer_sensor_periods_features(train, periods, feature_name):\n",
    "    train[f\"{feature_name}_rolling_mean_{periods}\"] = train[feature_name].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_rolling_sum_{periods}\"] = train[feature_name].rolling(periods,center=True).sum().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_rolling_max_{periods}\"] = train[feature_name].rolling(periods,center=True).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_rolling_min_{periods}\"] = train[feature_name].rolling(periods,center=True).min().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_rolling_std_{periods}\"] = train[feature_name].rolling(periods,center=True).std().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_rolling_median_{periods}\"] = train[feature_name].rolling(periods,center=True).median().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_rolling_variance_{periods}\"] = train[feature_name].rolling(periods,center=True).var().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "\n",
    "    quantiles = [0.25, 0.75]\n",
    "    for quantile in quantiles:\n",
    "        train[f\"{feature_name}_rolling_{int(quantile * 100)}th_percentile_{periods}\"] = train[feature_name].rolling(periods,center=True).quantile(quantile).fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "\n",
    "    train[f\"{feature_name}_diff_{periods}\"] = train[feature_name].diff(periods=periods).fillna(method=\"bfill\").astype('float32')\n",
    "\n",
    "    train[f\"{feature_name}_diff_rolling_mean_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_diff_rolling_sum_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=True).sum().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_diff_rolling_max_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=True).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_diff_rolling_min_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=True).min().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_diff_rolling_std_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=True).std().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_diff_rolling_median_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=True).median().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_diff_rolling_variance_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=True).var().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "\n",
    "    quantiles = [0.25, 0.75]\n",
    "    for quantile in quantiles:\n",
    "        train[f\"{feature_name}_diff_rolling_{int(quantile * 100)}th_percentile_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=True).quantile(quantile).fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "\n",
    "    return train\n",
    "\n",
    "def get_train_series(series):\n",
    "    train_series = pd.read_parquet(\"C:/Users/jonas.hodel/Downloads/train_series/train_series.parquet\", filters=[('series_id','=',series)])\n",
    "    train_events = pd.read_csv(\"C:/Users/jonas.hodel/Downloads/child-mind-institute-detect-sleep-states/train_events.csv\").query('series_id == @series')\n",
    "\n",
    "    train_events = engineer_wearable_on_on_train_events(train_events)\n",
    "\n",
    "    train_events = fill_step_on_train_events_when_nan(train_events)\n",
    "\n",
    "    train_events = engineer_awake_on_train_events(train_events)\n",
    "\n",
    "    train = pd.merge(train_series, train_events[['step','awake', 'wearable_on']], on='step', how='left')\n",
    "\n",
    "    train = engineer_awake_on_train(train)\n",
    "\n",
    "    train = engineer_wearable_on_on_train(train)\n",
    "    \n",
    "    train = split_timestamp_on_train(train)\n",
    "\n",
    "    train = engineer_anglez_features(train, [12, 60])\n",
    "\n",
    "    train = engineer_enmo_features(train, [12, 60])\n",
    "\n",
    "    return train\n",
    "\n",
    "\n",
    "def methodFromJonas(batch_size, test_series_path):\n",
    "    #train_series = pd.read_csv(\"C:/Users/jonas.hodel/Downloads/train_series/train_series.parquet\")\n",
    "    train_series = pd.read_csv(test_series_path)\n",
    "    series_ids = train_series['series_id'].unique()\n",
    "\n",
    "    batch = pd.DataFrame([])\n",
    "\n",
    "    for series_id in series_ids:\n",
    "        if batch.empty:\n",
    "            batch = get_train_series(series_id)\n",
    "        else:\n",
    "            batch = pd.concat([batch, get_train_series(series_id)])\n",
    "\n",
    "        if len(batch) >= batch_size:\n",
    "            yield batch\n",
    "            del batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def batched_dataloader(batch_size=100_000):\n",
    "#     dataset = ds.dataset(TEST_DATA)\n",
    "#     for fragment in dataset.get_fragments():\n",
    "#         batches = fragment.to_batches(batch_size=batch_size) # https://arrow.apache.org/docs/python/generated/pyarrow.dataset.Fragment.html#pyarrow.dataset.Fragment.to_batches\n",
    "#         for batch in batches:\n",
    "#             yield batch.to_pandas()\n",
    "#             del batch\n",
    "#         del fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1_PATH = 'models/model_1.pkl'\n",
    "M2_PATH = 'models/model_2.pkl'\n",
    "\n",
    "def load_model(name: str) -> RandomForestClassifier:\n",
    "    with open(name, 'rb') as f:\n",
    "        return load(f)\n",
    "\n",
    "m1 = load_model(M1_PATH)\n",
    "m2 = load_model(M1_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1_000_000\n",
    "TEST_DATA_PATH = ''\n",
    "submission_df = pd.Dataframe(columns=['row_id','series_id','step','event','score'])\n",
    "\n",
    "for batch in methodFromJonas(BATCH_SIZE, TEST_DATA_PATH):\n",
    "    batch = batch.drop(['wearable_on', 'awake', 'series_id'])\n",
    "    pred = m1.predict(batch, not_scaled=False)\n",
    "    batch['pred_wearable'] = pred\n",
    "    batch = batch[batch['pred_wearable'] == 1]\n",
    "    pred_2 = m2.predict(batch, not_scaled=False)\n",
    "    batch['pred_awake'] = pred_2\n",
    "\n",
    "    # heuristics\n",
    "    # transform for submission\n",
    "    submission_df = pd.concat([submission_df, \"\"\"TRANSFORMED\"\"\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False, encoding='utf-8', lineterminator='\\n')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
