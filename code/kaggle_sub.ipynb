{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from fx import *\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M1_PATH = 'models/AAAA.pkl'\n",
    "# M2_PATH = 'models/BBBB.pkl'\n",
    "M1_PATH = '/Users/ra/Library/CloudStorage/OneDrive-HochschuleLuzern/AICH/models/AAAA.pkl'\n",
    "M2_PATH = '/Users/ra/Library/CloudStorage/OneDrive-HochschuleLuzern/AICH/models/BBBB.pkl'\n",
    "\n",
    "\n",
    "def load_model(name: str) -> RandomForestClassifier:\n",
    "    with open(name, 'rb') as f:\n",
    "        return load(f)\n",
    "\n",
    "m1 = load_model(M1_PATH)\n",
    "m2 = load_model(M2_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "BATCH_SIZE = 1_000_000\n",
    "TEST_DATA_PATH = '../data/train_series.parquet'\n",
    "DEBUG = False\n",
    "submission_df = pd.DataFrame(columns=['series_id','step','event','score'])\n",
    "\n",
    "\n",
    "if not 'series_id_mapping' in vars():\n",
    "    series_id_mapping = dict()\n",
    "    t = ds.dataset(TEST_DATA_PATH).to_table(columns=['series_id'])\n",
    "    for i, data in enumerate(t.to_pandas()['series_id'].unique()):\n",
    "        series_id_mapping[data] = i\n",
    "    del t\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "for batch in methodFromJonas(BATCH_SIZE, TEST_DATA_PATH):\n",
    "    try:\n",
    "        # map series_id to int\n",
    "        batch['series_id'] = batch['series_id'].map(series_id_mapping)\n",
    "        # predict waerable_on\n",
    "        pred = m1.predict(batch)\n",
    "        batch['pred_worn'] = pred\n",
    "        # predict awake\n",
    "        batch = batch[batch['pred_worn'] == 1]\n",
    "        pred_2 = m2.predict(batch)\n",
    "        batch['pred_awake'] = pred_2\n",
    "        # undo mapping\n",
    "        reverse_mapped = dict((v,k) for k,v in series_id_mapping.items())\n",
    "        batch['series_id'] = batch['series_id'].apply(lambda x: reverse_mapped[x])\n",
    "        # use heuristic function\n",
    "        pre_sub = heuristic_function(batch)\n",
    "        # append to submission_df\n",
    "        submission_df = pd.concat([submission_df, pre_sub[['series_id','step','event','score']]])\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solves row_id problems\n",
    "submission_df = submission_df.reset_index(drop=True).reset_index(names=\"row_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False, encoding='utf-8', lineterminator='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aich",
   "language": "python",
   "name": "aich"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
