{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_events_csv = '../data/train_events.csv'\n",
    "path_sensor_parquet = '../data/train_series.parquet'\n",
    "drop_path = '../data/engineered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_step_on_train_events_when_nan(train_events): \n",
    "    last_value = 0\n",
    "\n",
    "    # loop over all event entries\n",
    "    for index, data in train_events.iterrows():\n",
    "        \n",
    "        # check if step is set\n",
    "        if pd.isnull(data['step']):\n",
    "\n",
    "            # set step with previous value + 1\n",
    "            train_events.at[index, 'step'] = last_value + 1\n",
    "        \n",
    "        # update last step value\n",
    "        last_value = train_events.at[index, 'step']\n",
    "\n",
    "    # set datatype for step\n",
    "    train_events[\"step\"]  = train_events[\"step\"].astype(\"int\")\n",
    "    \n",
    "    return train_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_awake_on_train_events(train_events):\n",
    "    # set awake = 1 when onset event and awake = 0 when wakeup event\n",
    "    train_events[\"awake\"] = train_events[\"event\"].replace({\"onset\":1,\"wakeup\":0})\n",
    "    \n",
    "    # set onset = 1 when onset event and onset = 0 when wakeup event\n",
    "    train_events[\"onset\"] = train_events[\"event\"].replace({\"onset\":1,\"wakeup\":0})\n",
    "    # fill null values in onset with 0\n",
    "    train_events[\"onset\"].fillna(0)\n",
    "    \n",
    "    # set wakeup = 1 when onset event and wakeup = 0 when wakeup event\n",
    "    train_events[\"wakeup\"] = train_events[\"event\"].replace({\"onset\":0,\"wakeup\":1})\n",
    "    # fill null values in wakeup with 0\n",
    "    train_events[\"wakeup\"].fillna(0)\n",
    "    \n",
    "    return train_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_wearable_on_on_train_events(train_events):\n",
    "    # init new feature wearable_on and set it to 1 for all events\n",
    "    train_events['wearable_on'] = 1\n",
    "    # if a event has no step then set the wearable_on to 0\n",
    "    train_events.loc[train_events['step'].isna(), 'wearable_on'] = 0    \n",
    "\n",
    "    return train_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_awake_on_train(train):\n",
    "    # fill the null values in wake\n",
    "    train[\"awake\"].bfill(axis ='rows', inplace=True)\n",
    "    train['awake'].fillna(1, inplace=True)\n",
    "    \n",
    "    # set datatype for awake\n",
    "    train[\"awake\"] = train[\"awake\"].astype(\"int\")\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_wearable_on_on_train(train):\n",
    "    # define new temporary feature which fills the null values in wearable_on with bfill first\n",
    "    train[\"wearable_on_temp1\"] = train[\"wearable_on\"]\n",
    "    train[\"wearable_on_temp1\"].bfill(inplace=True)\n",
    "    train[\"wearable_on_temp1\"].ffill(inplace=True)\n",
    "\n",
    "    # define new temporary feature which fills the null values in wearable_on with ffill first\n",
    "    train[\"wearable_on_temp2\"] = train[\"wearable_on\"]\n",
    "    train[\"wearable_on_temp2\"].ffill(inplace=True)\n",
    "    train[\"wearable_on_temp2\"].bfill(inplace=True)\n",
    "\n",
    "    # define 5min rolling window in both directions and calculate the std\n",
    "    train['enmo_5min_std_forward'] = train[\"enmo\"].rolling(720).std()\n",
    "    train['enmo_5min_std_backward'] = train[\"enmo\"][::-1].rolling(720).std()\n",
    "\n",
    "    # calculate the average std over both rolling windows\n",
    "    train['enmo_5min_std'] = (train['enmo_5min_std_backward'] + train['enmo_5min_std_forward']) / 2\n",
    "\n",
    "    # define wearable_on given the temporary engineered features\n",
    "    train[\"wearable_on\"] = ((train[\"wearable_on_temp1\"] == 1) & (train[\"wearable_on_temp2\"] == 1)) | (train['enmo_5min_std'] > 0.05)\n",
    "\n",
    "    # drop temporary features\n",
    "    train.drop('wearable_on_temp1', axis='columns', inplace=True)\n",
    "    train.drop('wearable_on_temp2', axis='columns', inplace=True)\n",
    "    train.drop('enmo_5min_std_forward', axis='columns', inplace=True)\n",
    "    train.drop('enmo_5min_std_backward', axis='columns', inplace=True)\n",
    "    train.drop('enmo_5min_std', axis='columns', inplace=True)\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_timestamp_on_train(train):\n",
    "    # split the timestamp into features\n",
    "    train['hour'] = train['timestamp'].dt.hour\n",
    "    train['minute'] = train['timestamp'].dt.minute\n",
    "    train['seconds'] = train['timestamp'].dt.second\n",
    "\n",
    "    train['day'] = train['timestamp'].dt.day\n",
    "    train['month'] = train['timestamp'].dt.month\n",
    "    train['year'] = train['timestamp'].dt.year\n",
    "\n",
    "    # drop timestamp\n",
    "    train.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "    train = train.reset_index()\n",
    "\n",
    "    train.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_anglez_features(train, periods):\n",
    "    # engineer features for anglez\n",
    "    return engineer_sensor_features(train, periods, 'anglez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_enmo_features(train, periods):\n",
    "    # engineer features for enmo\n",
    "    return engineer_sensor_features(train, periods, 'enmo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_sensor_features(train, periods, feature_name):\n",
    "    # engineer absolut value feature\n",
    "    train[f\"{feature_name}_abs\"] = abs(train[feature_name]).astype(\"float32\")\n",
    "\n",
    "    # engineer rolling windows\n",
    "    for period in periods:\n",
    "        train = engineer_sensor_periods_features(train, period, feature_name)\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_sensor_periods_features(train, periods, feature_name):\n",
    "    train[f\"{feature_name}_rolling_mean_{periods}\"] = train[feature_name].rolling(periods,center=False).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    # train[f\"{feature_name}_rolling_sum_{periods}\"] = train[feature_name].rolling(periods,center=True).sum().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_rolling_max_{periods}\"] = train[feature_name].rolling(periods,center=False).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    # train[f\"{feature_name}_rolling_min_{periods}\"] = train[feature_name].rolling(periods,center=True).min().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_rolling_std_{periods}\"] = train[feature_name].rolling(periods,center=False).std().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    # train[f\"{feature_name}_rolling_median_{periods}\"] = train[feature_name].rolling(periods,center=True).median().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    # train[f\"{feature_name}_rolling_variance_{periods}\"] = train[feature_name].rolling(periods,center=True).var().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "\n",
    "    # quantiles = [0.25, 0.75]\n",
    "    # for quantile in quantiles:\n",
    "    #     train[f\"{feature_name}_rolling_{int(quantile * 100)}th_percentile_{periods}\"] = train[feature_name].rolling(periods,center=True).quantile(quantile).fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "\n",
    "    train[f\"{feature_name}_diff_{periods}\"] = train[feature_name].diff(periods=periods).fillna(method=\"bfill\").astype('float32')\n",
    "\n",
    "    train[f\"{feature_name}_diff_rolling_mean_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=False).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    # train[f\"{feature_name}_diff_rolling_sum_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=True).sum().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_diff_rolling_max_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=False).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    # train[f\"{feature_name}_diff_rolling_min_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=True).min().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    train[f\"{feature_name}_diff_rolling_std_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=False).std().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    # train[f\"{feature_name}_diff_rolling_median_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=True).median().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "    # train[f\"{feature_name}_diff_rolling_variance_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=True).var().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "\n",
    "    # quantiles = [0.25, 0.75]\n",
    "    # for quantile in quantiles:\n",
    "    #     train[f\"{feature_name}_diff_rolling_{int(quantile * 100)}th_percentile_{periods}\"] = train[f\"{feature_name}_diff_{periods}\"].rolling(periods,center=True).quantile(quantile).fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float32')\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_data(train):\n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'].str[:-5])\n",
    "\n",
    "    custom_agg_function = lambda x: round(sum(x) / len(x)) if len(x) > 0 else 1\n",
    "\n",
    "    # bin the data into 1Min blocks\n",
    "    binned_df = train.resample('1Min', on='timestamp').agg({\n",
    "        'series_id': 'first',\n",
    "        'step': 'first',\n",
    "        'awake': custom_agg_function,\n",
    "        'wearable_on': custom_agg_function,\n",
    "        'anglez': 'mean',\n",
    "        'enmo': 'mean',\n",
    "        'timestamp': 'first'\n",
    "    })\n",
    "\n",
    "    binned_df.dropna(inplace=True)\n",
    "\n",
    "    return binned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_previous_and_next_nights(train):\n",
    "    entries_one_night = 1440\n",
    "    entires_two_nights = 2880\n",
    "\n",
    "    # get all columns to compare with\n",
    "    enmo_column_names = [col for col in train.columns if 'enmo' in col]\n",
    "    anglez_column_names = [col for col in train.columns if 'anglez' in col]\n",
    "    \n",
    "    column_names = enmo_column_names + anglez_column_names\n",
    "\n",
    "    # define the new column names\n",
    "    new_columns = [(col, \n",
    "                    f'shift_1_d_past_{col}', \n",
    "                    f'shift_diff_1_d_past_{col}', \n",
    "                    f'shift_2_d_past_{col}', \n",
    "                    f'shift_diff_2_d_past_{col}',\n",
    "                    f'shift_1_d_future_{col}',\n",
    "                    f'shift_diff_1_d_future_{col}',\n",
    "                    f'shift_2_d_future_{col}',\n",
    "                    f'shift_diff_2_d_future_{col}'\n",
    "                    ) for col in column_names]\n",
    "    \n",
    "    for (column_name, \n",
    "        shift_1_d_past, \n",
    "        shift_diff_1_d_past, \n",
    "        shift_2_d_past, \n",
    "        shift_diff_2_d_past, \n",
    "        shift_1_d_future, \n",
    "        shift_diff_1_d_future, \n",
    "        shift_2_d_future, \n",
    "        shift_diff_2_d_future) in new_columns: \n",
    "\n",
    "        # create the new lag features with diffrence\n",
    "        train[shift_1_d_past] = train.shift(-entries_one_night)[column_name]\n",
    "        train[shift_diff_1_d_past] = train[shift_1_d_past] - train[column_name]\n",
    "\n",
    "        train[shift_2_d_past] = train.shift(-entires_two_nights)[column_name]\n",
    "        train[shift_diff_2_d_past] = train[shift_2_d_past] - train[column_name]\n",
    "\n",
    "        train[shift_1_d_future] = train.shift(-entries_one_night)[column_name]\n",
    "        train[shift_diff_1_d_future] = train[shift_1_d_future] - train[column_name]\n",
    "\n",
    "        train[shift_2_d_future] = train.shift(-entires_two_nights)[column_name]\n",
    "        train[shift_diff_2_d_future] = train[shift_2_d_future] - train[column_name]\n",
    "\n",
    "    train.dropna(inplace=True)\n",
    "\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_series(series):\n",
    "    train_series = pd.read_parquet(path_sensor_parquet, filters=[('series_id','=',series)])\n",
    "    \n",
    "    train_events = pd.read_csv(path_events_csv).query('series_id == @series')\n",
    "\n",
    "    train_events = engineer_wearable_on_on_train_events(train_events)\n",
    "\n",
    "    train_events = fill_step_on_train_events_when_nan(train_events)\n",
    "\n",
    "    train_events = engineer_awake_on_train_events(train_events)\n",
    "\n",
    "    train = pd.merge(train_series, train_events[['step','awake', 'wearable_on']], on='step', how='left')\n",
    "\n",
    "    train = engineer_awake_on_train(train)\n",
    "\n",
    "    train = engineer_wearable_on_on_train(train)\n",
    "\n",
    "    train = bin_data(train)\n",
    "    \n",
    "    train = split_timestamp_on_train(train)\n",
    "\n",
    "    train = engineer_anglez_features(train, [5, 30, 120, 480])\n",
    "\n",
    "    train = engineer_enmo_features(train, [5, 30, 120, 480])\n",
    "\n",
    "    # train = shift_previous_and_next_nights(train)\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exectute feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1_000_000\n",
    "train_events = pd.read_csv(path_events_csv)\n",
    "\n",
    "series_ids = train_events['series_id'].unique()\n",
    "\n",
    "batch = pd.DataFrame([])\n",
    "\n",
    "series_count = 0\n",
    "batch_count = 0\n",
    "for series_id in series_ids:\n",
    "    print(f'{series_count} {series_id}')\n",
    "    if batch.empty:\n",
    "        batch = get_train_series(series_id)\n",
    "    else:\n",
    "        batch = pd.concat([batch, get_train_series(series_id)])\n",
    "\n",
    "        if len(batch) >= batch_size:\n",
    "            batch.to_parquet(f'{drop_path}/{batch_count}.parquet')\n",
    "            batch = pd.DataFrame([])\n",
    "            batch_count += 1\n",
    "\n",
    "    series_count += 1\n",
    "\n",
    "batch.to_parquet(f'{drop_path}/{batch_count}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into val and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(drop_path)\n",
    "\n",
    "val_fence = round(len(files) * 0.2)\n",
    "\n",
    "for filename in files:\n",
    "    if filename.endswith('.parquet'):\n",
    "        if int(filename.removesuffix('.parquet')) < val_fence:\n",
    "            shutil.move(f'{drop_path}/{filename}', f'{drop_path}/val/{filename}')\n",
    "        else: \n",
    "            shutil.move(f'{drop_path}/{filename}', f'{drop_path}/train/{filename}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
